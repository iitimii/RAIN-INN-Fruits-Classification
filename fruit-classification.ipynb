{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5350598,"sourceType":"datasetVersion","datasetId":3106263},{"sourceId":86928,"sourceType":"modelInstanceVersion","modelInstanceId":73009,"modelId":97888}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Dropout, GlobalAveragePooling2D\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-02T20:27:23.299672Z","iopub.execute_input":"2024-08-02T20:27:23.300141Z","iopub.status.idle":"2024-08-02T20:27:23.307625Z","shell.execute_reply.started":"2024-08-02T20:27:23.300104Z","shell.execute_reply":"2024-08-02T20:27:23.306403Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model):\n    train_loss, train_accuracy = model.evaluate(orig_train_data, verbose=2)\n    print(f\"Train Loss: {train_loss}\")\n    print(f\"Train Accuracy: {train_accuracy}\")\n\n    val_loss, val_accuracy = model.evaluate(val_data, verbose=2)\n    print(f\"Validation Loss: {val_loss}\")\n    print(f\"Validation Accuracy: {val_accuracy}\")\n\n    test_loss, test_accuracy = model.evaluate(test_data, verbose=2)\n    print(f\"Test Loss: {test_loss}\")\n    print(f\"Test Accuracy: {test_accuracy}\")\n\ndef plot_metrics(history, metric):\n    plt.plot(history.history[metric], label='Train accuracy')\n    plt.plot(history.history['val_'+metric], label='Validation accuracy')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:53:03.840366Z","iopub.execute_input":"2024-08-02T20:53:03.840743Z","iopub.status.idle":"2024-08-02T20:53:03.847927Z","shell.execute_reply.started":"2024-08-02T20:53:03.840715Z","shell.execute_reply":"2024-08-02T20:53:03.846874Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Loading data from dataset using ImageDataGenerator\n- Data augmentation is introduced in the pipeline for loading the train data. This helps to combat overfitting (as seen in the sample model in https://www.kaggle.com/code/ekanemgodwin/fruit-classification-test)","metadata":{}},{"cell_type":"code","source":"train_dir = \"/kaggle/input/fruits-classification/Fruits Classification/train\"\ntrain_data_gen = ImageDataGenerator(rescale=1/255,\n                                rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\ntrain_data = train_data_gen.flow_from_directory(train_dir,\n                           batch_size=64,\n                           class_mode='categorical',\n                           target_size=(150, 150))","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:07:39.802172Z","iopub.execute_input":"2024-08-02T20:07:39.802535Z","iopub.status.idle":"2024-08-02T20:07:50.670083Z","shell.execute_reply.started":"2024-08-02T20:07:39.802494Z","shell.execute_reply":"2024-08-02T20:07:50.669354Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 9700 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Train data without augmentation (for evaluation purpose down the line)\norig_train_data_gen = ImageDataGenerator(rescale=1/255)\norig_train_data = orig_train_data_gen.flow_from_directory(train_dir,\n                           batch_size=64,\n                           class_mode='categorical',\n                           target_size=(150, 150))","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:36:28.107055Z","iopub.execute_input":"2024-08-02T20:36:28.107815Z","iopub.status.idle":"2024-08-02T20:36:30.247142Z","shell.execute_reply.started":"2024-08-02T20:36:28.107782Z","shell.execute_reply":"2024-08-02T20:36:30.246239Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 9700 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"val_dir = \"/kaggle/input/fruits-classification/Fruits Classification/valid\"\nval_data_gen = ImageDataGenerator(rescale=1/255)\n\nval_data = val_data_gen.flow_from_directory(val_dir,\n                                           batch_size=32,\n                                           class_mode='categorical',\n                                           target_size=(150, 150))","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:07:50.671811Z","iopub.execute_input":"2024-08-02T20:07:50.672411Z","iopub.status.idle":"2024-08-02T20:07:50.716061Z","shell.execute_reply.started":"2024-08-02T20:07:50.672374Z","shell.execute_reply":"2024-08-02T20:07:50.715375Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 200 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dir = \"/kaggle/input/fruits-classification/Fruits Classification/test\"\ntest_data_gen = ImageDataGenerator(rescale=1/255)\ntest_data = test_data_gen.flow_from_directory(test_dir,\n                                             batch_size=32,\n                                             class_mode='categorical',\n                                             target_size=(150, 150))","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:07:50.717023Z","iopub.execute_input":"2024-08-02T20:07:50.717309Z","iopub.status.idle":"2024-08-02T20:07:50.756555Z","shell.execute_reply.started":"2024-08-02T20:07:50.717285Z","shell.execute_reply":"2024-08-02T20:07:50.755249Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 100 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model1:\n- Experimenting with more layers compared to sample model (https://www.kaggle.com/code/ekanemgodwin/fruit-classification-test) to see performance","metadata":{}},{"cell_type":"code","source":"model1 = Sequential([\n    Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D(2, 2),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(512, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(128, activation='relu'),\n    Dense(5, activation='softmax')\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T15:02:18.049165Z","iopub.execute_input":"2024-08-01T15:02:18.049576Z","iopub.status.idle":"2024-08-01T15:02:18.157830Z","shell.execute_reply.started":"2024-08-01T15:02:18.049545Z","shell.execute_reply":"2024-08-01T15:02:18.156993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T15:03:06.394926Z","iopub.execute_input":"2024-08-01T15:03:06.395305Z","iopub.status.idle":"2024-08-01T15:03:06.405603Z","shell.execute_reply.started":"2024-08-01T15:03:06.395274Z","shell.execute_reply":"2024-08-01T15:03:06.404538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history1 = model1.fit(train_data,\n         epochs=30,\n         validation_data=val_data,\n         verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T15:03:26.629413Z","iopub.execute_input":"2024-08-01T15:03:26.629806Z","iopub.status.idle":"2024-08-01T15:33:30.614787Z","shell.execute_reply.started":"2024-08-01T15:03:26.629775Z","shell.execute_reply":"2024-08-01T15:33:30.613796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.save('model1.keras')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T15:34:05.466900Z","iopub.execute_input":"2024-08-01T15:34:05.467806Z","iopub.status.idle":"2024-08-01T15:34:05.603624Z","shell.execute_reply.started":"2024-08-01T15:34:05.467767Z","shell.execute_reply":"2024-08-01T15:34:05.602806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = load_model(\"/kaggle/working/model1.keras\")\nevaluate_model(model1)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:45:28.613943Z","iopub.execute_input":"2024-08-02T20:45:28.614841Z","iopub.status.idle":"2024-08-02T20:45:43.386056Z","shell.execute_reply.started":"2024-08-02T20:45:28.614807Z","shell.execute_reply":"2024-08-02T20:45:43.385105Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"152/152 - 14s - 91ms/step - accuracy: 0.7886 - loss: 0.5552\nTrain Loss: 0.5552327036857605\nTrain Accuracy: 0.788556694984436\n7/7 - 0s - 41ms/step - accuracy: 0.7400 - loss: 0.7044\nValidation Loss: 0.704437255859375\nValidation Accuracy: 0.7400000095367432\n4/4 - 0s - 41ms/step - accuracy: 0.7700 - loss: 0.6008\nTest Loss: 0.6007728576660156\nTest Accuracy: 0.7699999809265137\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From the results above, having trained for longer epochs with the larger model architecture, the train accuracy (78%) doesn't differ as much from validation accuracy (74%), showing effect of data augmentation in preventing overfitting","metadata":{}},{"cell_type":"markdown","source":"# Experimenting with MobileNetV2 (Transfer Learning)\n- The feature extraction layers will be loaded and frozen (the top layers are excluded)\n- Extra layers are added, tailored towards our application","metadata":{}},{"cell_type":"code","source":"base_model = MobileNetV2(input_shape = (150, 150, 3),\n                  weights='imagenet',\n                  include_top=False)\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:07:14.655416Z","iopub.execute_input":"2024-08-02T20:07:14.656330Z","iopub.status.idle":"2024-08-02T20:07:15.696453Z","shell.execute_reply.started":"2024-08-02T20:07:14.656297Z","shell.execute_reply":"2024-08-02T20:07:15.695724Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1548143176.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base_model = MobileNetV2(input_shape = (150, 150, 3),\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = Input(shape=(150, 150, 3))\nx = base_model(inputs)\nx = Flatten()(x)\nx = Dense(512, activation='relu')(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutputs = Dense(5, activation='softmax')(x)\n\nmodel2 = Model(inputs=inputs, outputs=outputs)\nmodel2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:10:42.140772Z","iopub.execute_input":"2024-08-01T14:10:42.141150Z","iopub.status.idle":"2024-08-01T14:10:42.205067Z","shell.execute_reply.started":"2024-08-01T14:10:42.141120Z","shell.execute_reply":"2024-08-01T14:10:42.204180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n    ModelCheckpoint(\"model2.keras\", monitor='val_accuracy', save_best_only=True)\n]\nhistory2 = model2.fit(train_data,\n         epochs=50,\n         validation_data=val_data,\n         callbacks=callbacks,\n         verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:16:54.162327Z","iopub.execute_input":"2024-08-01T14:16:54.162719Z","iopub.status.idle":"2024-08-01T14:27:51.165138Z","shell.execute_reply.started":"2024-08-01T14:16:54.162688Z","shell.execute_reply":"2024-08-01T14:27:51.163819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = load_model(\"/kaggle/working/model2.keras\")\nevaluate_model(model2)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:46:53.814177Z","iopub.execute_input":"2024-08-02T20:46:53.814815Z","iopub.status.idle":"2024-08-02T20:47:23.604395Z","shell.execute_reply.started":"2024-08-02T20:46:53.814783Z","shell.execute_reply":"2024-08-02T20:47:23.603443Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"W0000 00:00:1722631620.031734      80 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"152/152 - 19s - 128ms/step - accuracy: 0.9371 - loss: 0.2033\nTrain Loss: 0.2032615840435028\nTrain Accuracy: 0.9371134042739868\n7/7 - 4s - 623ms/step - accuracy: 0.8650 - loss: 0.3868\nValidation Loss: 0.3867763876914978\nValidation Accuracy: 0.8650000095367432\n4/4 - 4s - 975ms/step - accuracy: 0.9000 - loss: 0.3111\nTest Loss: 0.311073362827301\nTest Accuracy: 0.8999999761581421\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1722631643.592491      80 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From the above results, there is a significant increase in accuracy. \n- However, in the above model, a `Flatten` layer was used to reduce the dimensions from the feature extraction layers (MobileNetV2 layers). \n- The model below will use a `GlobalAveragePooling2D` layer to reduce the dimensions (an experiment to see performace, referenced from https://www.kaggle.com/code/utkarshsaxenadn/fruit-classification-mobilenetv2-acc-95)\n- A dropout layer is added before final layer to also combat overfitting\n- Callbacks are implemented, monitoring validation accuracy for 5 epochs and stopping training if there is no improvement in that time","metadata":{}},{"cell_type":"code","source":"inputs = Input(shape=(150, 150, 3))\nx = base_model(inputs)\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutputs = Dense(5, activation='softmax')(x)\n\nmodel3 = Model(inputs=inputs, outputs=outputs)\nmodel3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel3.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:36:29.883495Z","iopub.execute_input":"2024-08-01T14:36:29.883874Z","iopub.status.idle":"2024-08-01T14:36:29.944146Z","shell.execute_reply.started":"2024-08-01T14:36:29.883841Z","shell.execute_reply":"2024-08-01T14:36:29.943299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n    ModelCheckpoint(\"model3.keras\", monitor='val_accuracy', save_best_only=True)\n]\nhistory3 = model3.fit(train_data,\n         epochs=50,\n         validation_data=val_data,\n         callbacks=callbacks,\n         verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:36:47.883318Z","iopub.execute_input":"2024-08-01T14:36:47.884210Z","iopub.status.idle":"2024-08-01T14:56:11.214233Z","shell.execute_reply.started":"2024-08-01T14:36:47.884177Z","shell.execute_reply":"2024-08-01T14:56:11.212974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = load_model(\"/kaggle/working/model3.keras\")\nevaluate_model(model3)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:58:28.426098Z","iopub.execute_input":"2024-08-02T20:58:28.427059Z","iopub.status.idle":"2024-08-02T20:58:53.291242Z","shell.execute_reply.started":"2024-08-02T20:58:28.427025Z","shell.execute_reply":"2024-08-02T20:58:53.290284Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"W0000 00:00:1722632313.502337      80 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"152/152 - 18s - 120ms/step - accuracy: 0.9085 - loss: 0.2523\nTrain Loss: 0.2523084878921509\nTrain Accuracy: 0.9084535837173462\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1722632329.665823      78 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"7/7 - 3s - 496ms/step - accuracy: 0.9100 - loss: 0.2768\nValidation Loss: 0.27681341767311096\nValidation Accuracy: 0.9100000262260437\n4/4 - 2s - 424ms/step - accuracy: 0.8800 - loss: 0.2847\nTest Loss: 0.2847316861152649\nTest Accuracy: 0.8799999952316284\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The use of `GlobalAveragePooling2D` layer seems to have a slightly better performance ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}